{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/02 19:09:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark: SparkSession = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .enableHiveSupport() # type: ignore\n",
    "    .master('local[*]')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/02 19:09:33 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/04/02 19:09:33 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "25/04/02 19:09:39 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "25/04/02 19:09:39 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore sucol@192.168.1.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|ingestion|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/02 19:09:49 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+\n",
      "|namespace| tableName|isTemporary|\n",
      "+---------+----------+-----------+\n",
      "|ingestion|     order|      false|\n",
      "|ingestion|order_item|      false|\n",
      "|ingestion|   product|      false|\n",
      "|ingestion|      user|      false|\n",
      "+---------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN ingestion\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------------+---------+-----------+-------------------+-------------------+\n",
      "| id|user_id|         order_date|   status|total_value|      creation_date| ingestion_datetime|\n",
      "+---+-------+-------------------+---------+-----------+-------------------+-------------------+\n",
      "|  1|      2|2024-12-07 18:44:57|  shipped|     1953.0|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "|  2|      1|2024-08-06 18:44:57|  pending|    5842.57|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "|  3|      2|2025-01-31 18:44:57| canceled|     2441.8|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "|  4|      1|2024-08-30 18:44:57| approved|    1208.68|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "|  5|      2|2024-04-02 18:44:57|delivered|    1583.34|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "|  6|      1|2024-12-01 18:44:57|  shipped|    7614.99|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "|  7|      1|2024-09-10 18:44:57|  shipped|    3779.53|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "|  8|      2|2024-12-07 18:44:57| approved|    5164.41|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "|  9|      2|2024-06-15 18:44:57|  pending|    1308.03|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "| 10|      2|2024-10-12 18:44:57|  pending|    3656.84|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "| 11|      2|2025-01-01 18:44:57|  pending|    3514.02|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "| 12|      2|2025-02-25 18:44:57|  shipped|    5378.52|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "| 13|      1|2024-05-03 18:44:57|  shipped|    2451.52|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "| 14|      1|2024-08-08 18:44:57|  shipped|     5195.0|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "| 15|      1|2025-03-08 18:44:57| approved|    4992.73|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "| 16|      1|2024-11-29 18:44:57|  shipped|    4535.18|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "| 17|      2|2025-04-01 18:44:57|  shipped|    3760.83|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "| 18|      2|2025-02-21 18:44:57| canceled|    3745.48|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "| 19|      1|2024-09-26 18:44:57|  pending|    2203.64|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "| 20|      1|2024-12-18 18:44:57|delivered|    4540.68|2025-04-02 18:44:56|2025-04-02 19:07:09|\n",
      "+---+-------+-------------------+---------+-----------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_order = spark.read.table(\"ingestion.order\")\n",
    "df_order.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------------+--------+-----------+-------------------+--------------------+\n",
      "| id|user_id|         order_date|  status|total_value|      creation_date|  ingestion_datetime|\n",
      "+---+-------+-------------------+--------+-----------+-------------------+--------------------+\n",
      "|  2|      1|2024-12-13 12:27:49|approved|      64.24|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 17|      1|2024-08-17 12:27:49|approved|    2587.44|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 20|      2|2025-03-28 12:27:49|approved|    1960.32|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 21|      1|2024-06-20 12:27:49|approved|    1085.54|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 26|      1|2024-10-29 12:27:49|approved|    1789.42|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 40|      1|2024-10-16 12:27:49|approved|     968.32|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 42|      2|2024-07-23 12:27:49|approved|    3580.78|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 43|      1|2024-12-21 12:27:49|approved|    2916.12|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 45|      1|2024-09-06 12:27:49|approved|    4250.42|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 46|      1|2024-04-17 12:27:49|approved|    3140.66|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 67|      1|2024-06-30 12:27:49|approved|     2464.2|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 83|      1|2024-04-30 12:27:49|approved|    3180.11|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 85|      1|2024-05-15 12:27:49|approved|    3033.63|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 86|      1|2025-01-29 12:27:49|approved|    1265.98|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 94|      2|2024-08-03 12:27:49|approved|    2940.86|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "| 96|      2|2024-12-21 12:27:49|approved|     680.19|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "|100|      2|2024-11-16 12:27:49|approved|    1823.41|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "|101|      2|2024-11-23 12:27:49|approved|    4568.66|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "|102|      1|2024-06-09 12:27:49|approved|     108.15|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "|103|      2|2025-01-04 12:27:49|approved|    1794.19|2025-03-30 12:27:49|2025-03-31 21:19:...|\n",
      "+---+-------+-------------------+--------+-----------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "is_approved = F.col('status') == \"approved\"\n",
    "df_approved_order = df_order.filter(is_approved)\n",
    "df_approved_order.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------------+--------+-----------+-------------------+--------------------+--------------------+\n",
      "| id|user_id|         order_date|  status|total_value|      creation_date|  ingestion_datetime|               email|\n",
      "+---+-------+-------------------+--------+-----------+-------------------+--------------------+--------------------+\n",
      "|  2|      1|2024-12-13 12:27:49|approved|      64.24|2025-03-30 12:27:49|2025-03-31 21:19:...|richardskim@examp...|\n",
      "| 17|      1|2024-08-17 12:27:49|approved|    2587.44|2025-03-30 12:27:49|2025-03-31 21:19:...|richardskim@examp...|\n",
      "| 21|      1|2024-06-20 12:27:49|approved|    1085.54|2025-03-30 12:27:49|2025-03-31 21:19:...|richardskim@examp...|\n",
      "| 26|      1|2024-10-29 12:27:49|approved|    1789.42|2025-03-30 12:27:49|2025-03-31 21:19:...|richardskim@examp...|\n",
      "| 40|      1|2024-10-16 12:27:49|approved|     968.32|2025-03-30 12:27:49|2025-03-31 21:19:...|richardskim@examp...|\n",
      "| 43|      1|2024-12-21 12:27:49|approved|    2916.12|2025-03-30 12:27:49|2025-03-31 21:19:...|richardskim@examp...|\n",
      "| 45|      1|2024-09-06 12:27:49|approved|    4250.42|2025-03-30 12:27:49|2025-03-31 21:19:...|richardskim@examp...|\n",
      "| 46|      1|2024-04-17 12:27:49|approved|    3140.66|2025-03-30 12:27:49|2025-03-31 21:19:...|richardskim@examp...|\n",
      "| 67|      1|2024-06-30 12:27:49|approved|     2464.2|2025-03-30 12:27:49|2025-03-31 21:19:...|richardskim@examp...|\n",
      "| 83|      1|2024-04-30 12:27:49|approved|    3180.11|2025-03-30 12:27:49|2025-03-31 21:19:...|richardskim@examp...|\n",
      "| 85|      1|2024-05-15 12:27:49|approved|    3033.63|2025-03-30 12:27:49|2025-03-31 21:19:...|richardskim@examp...|\n",
      "| 86|      1|2025-01-29 12:27:49|approved|    1265.98|2025-03-30 12:27:49|2025-03-31 21:19:...|richardskim@examp...|\n",
      "|102|      1|2024-06-09 12:27:49|approved|     108.15|2025-03-30 12:27:49|2025-03-31 21:19:...|richardskim@examp...|\n",
      "|106|      1|2024-10-18 12:27:49|approved|     2111.7|2025-03-30 12:27:49|2025-03-31 21:19:...|richardskim@examp...|\n",
      "| 20|      2|2025-03-28 12:27:49|approved|    1960.32|2025-03-30 12:27:49|2025-03-31 21:19:...|jimenezjoshua@exa...|\n",
      "| 42|      2|2024-07-23 12:27:49|approved|    3580.78|2025-03-30 12:27:49|2025-03-31 21:19:...|jimenezjoshua@exa...|\n",
      "| 94|      2|2024-08-03 12:27:49|approved|    2940.86|2025-03-30 12:27:49|2025-03-31 21:19:...|jimenezjoshua@exa...|\n",
      "| 96|      2|2024-12-21 12:27:49|approved|     680.19|2025-03-30 12:27:49|2025-03-31 21:19:...|jimenezjoshua@exa...|\n",
      "|100|      2|2024-11-16 12:27:49|approved|    1823.41|2025-03-30 12:27:49|2025-03-31 21:19:...|jimenezjoshua@exa...|\n",
      "|101|      2|2024-11-23 12:27:49|approved|    4568.66|2025-03-30 12:27:49|2025-03-31 21:19:...|jimenezjoshua@exa...|\n",
      "+---+-------+-------------------+--------+-----------+-------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user = spark.read.table(\"ingestion.user\")\n",
    "df_user = df_user.select('id', 'email')\n",
    "\n",
    "df_approved_order_with_user_email = df_approved_order.join(\n",
    "    df_user,\n",
    "    df_approved_order['user_id'] == df_user['id'],\n",
    "    'left'\n",
    ")\n",
    "\n",
    "df_approved_order_with_user_email = df_approved_order_with_user_email.select(\n",
    "    df_approved_order['*'],\n",
    "    df_user['email']\n",
    ")\n",
    "\n",
    "df_approved_order_with_user_email.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------+------------------+\n",
      "|user_id|               email|order_count|       total_value|\n",
      "+-------+--------------------+-----------+------------------+\n",
      "|     12|smithjose@example...|         13|          47176.85|\n",
      "|      1|richardskim@examp...|        206| 590675.7100000005|\n",
      "|     13| scott49@example.org|         16|          49640.61|\n",
      "|      6|victoriariddle@ex...|         27| 79803.23000000001|\n",
      "|     16|zacharymccoy@exam...|          2|            7696.3|\n",
      "|      3|kimberlygreen@exa...|         88| 271171.3199999999|\n",
      "|      5|byrdnicole@exampl...|         64|172332.34999999995|\n",
      "|     15|kimdonald@example...|          7|          21694.65|\n",
      "|      9| randy06@example.org|         35|117585.10999999999|\n",
      "|      4|amanda40@example.net|         70|212784.69000000012|\n",
      "|      8|thomasethan@examp...|         18| 68314.16999999998|\n",
      "|      7|kjohnson@example.org|         37|118297.11000000002|\n",
      "|     10|andreaperez@examp...|         28| 77400.16999999998|\n",
      "|     11|michael49@example...|          9|          26560.45|\n",
      "|     14|brittanyvelez@exa...|          6|          11579.63|\n",
      "|      2|jimenezjoshua@exa...|        164| 528625.2299999997|\n",
      "+-------+--------------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_grouped = (\n",
    "    df_approved_order_with_user_email\n",
    "    .groupBy('user_id', 'email')\n",
    "    .agg(\n",
    "        F.count('*').alias('order_count'),\n",
    "        F.sum('total_value').alias('total_value')\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/31 21:36:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/31 21:36:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/31 21:36:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/31 21:36:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/31 21:36:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/31 21:36:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/31 21:36:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/31 21:36:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/31 21:36:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------+-----------------+----+\n",
      "|user_id|               email|order_count|      total_value|rank|\n",
      "+-------+--------------------+-----------+-----------------+----+\n",
      "|      1|richardskim@examp...|        206|590675.7100000005|   1|\n",
      "|      2|jimenezjoshua@exa...|        164|528625.2299999997|   2|\n",
      "|      3|kimberlygreen@exa...|         88|271171.3199999999|   3|\n",
      "+-------+--------------------+-----------+-----------------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/31 21:36:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/03/31 21:36:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create a column rank based on total_value. The greater the total_value, the higher the rank\n",
    "df_ranked = df_grouped.selectExpr(\n",
    "    '*',\n",
    "    'rank() over (order by total_value desc) as rank'\n",
    ")\n",
    "\n",
    "is_top_3 = F.col('rank') <= 3\n",
    "df_top_3 = df_ranked.filter(is_top_3)\n",
    "\n",
    "df_top_3.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
